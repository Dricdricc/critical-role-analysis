{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import os\n",
    "import itertools\n",
    "import pathlib\n",
    "\n",
    "import contractions\n",
    "import nltk\n",
    "import inflect\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "actorList = ['MATT', 'MARISHA', 'TRAVIS', 'LAURA', 'SAM', 'LIAM', 'ASHLEY', 'TALIESIN', 'ORION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Using cached contractions-0.0.25-py2.py3-none-any.whl (3.2 kB)\n",
      "Collecting textsearch\n",
      "  Using cached textsearch-0.0.17-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: Unidecode in c:\\users\\edric\\anaconda3\\lib\\site-packages (from textsearch->contractions) (1.1.1)\n",
      "Collecting pyahocorasick\n",
      "  Using cached pyahocorasick-1.4.0.tar.gz (312 kB)\n",
      "Building wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py): started\n",
      "  Building wheel for pyahocorasick (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pyahocorasick\n",
      "Failed to build pyahocorasick\n",
      "Installing collected packages: pyahocorasick, textsearch, contractions\n",
      "    Running setup.py install for pyahocorasick: started\n",
      "    Running setup.py install for pyahocorasick: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\Edric\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Edric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-okdh4nfz\\\\pyahocorasick\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Edric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-okdh4nfz\\\\pyahocorasick\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\Edric\\AppData\\Local\\Temp\\pip-wheel-fw9hfj06'\n",
      "       cwd: C:\\Users\\Edric\\AppData\\Local\\Temp\\pip-install-okdh4nfz\\pyahocorasick\\\n",
      "  Complete output (5 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'ahocorasick' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pyahocorasick\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\Edric\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Edric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-okdh4nfz\\\\pyahocorasick\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Edric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-okdh4nfz\\\\pyahocorasick\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Edric\\AppData\\Local\\Temp\\pip-record-fgkjqotc\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\Edric\\anaconda3\\Include\\pyahocorasick'\n",
      "         cwd: C:\\Users\\Edric\\AppData\\Local\\Temp\\pip-install-okdh4nfz\\pyahocorasick\\\n",
      "    Complete output (5 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_ext\n",
      "    building 'ahocorasick' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\Edric\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Edric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-okdh4nfz\\\\pyahocorasick\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Edric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-okdh4nfz\\\\pyahocorasick\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Edric\\AppData\\Local\\Temp\\pip-record-fgkjqotc\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\Edric\\anaconda3\\Include\\pyahocorasick' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_between_parentheses(text):\n",
    "    return re.sub('\\([^()]*\\)', '', text)\n",
    "\n",
    "def remove_dice_rolls(text):\n",
    "    return re.sub('\\s?[0-9]+d[0-9]+\\s?', '', text)\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub('[0-9]+', text)\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences \n",
    "    in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each actor,\n",
    "for actor in actorList:\n",
    "    folderPath = 'data/ACTOR TREATED/{actor}'.format(actor = actor)\n",
    "    \n",
    "    for path in pathlib.Path(folderPath).iterdir():\n",
    "        \n",
    "        if path.is_file():\n",
    "            print(\"\\n{path}\".format(path = path))\n",
    "\n",
    "            #Open the file\n",
    "            current_file = open(path, \"r\", encoding = 'utf8')\n",
    "            \n",
    "            #Read the file\n",
    "            content = current_file.read()\n",
    "            current_file.close()\n",
    "            \n",
    "            #Remove parentheses\n",
    "            content_noActions = remove_between_parentheses(content)\n",
    "\n",
    "            #Remove dicerolls\n",
    "            content_noDice = remove_dice_rolls(content_noActions)\n",
    "\n",
    "            #Remove double hyphens\n",
    "            content_noHyphens = content_noDice.replace('--', '')\n",
    "\n",
    "            #Replace contractions\n",
    "            content_full = contractions.fix(content_noHyphens)\n",
    "\n",
    "            #Tokenize the content\n",
    "            tokens = nltk.word_tokenize(content_full)\n",
    "\n",
    "            #Remove stopwords\n",
    "            tokens_noStops = []\n",
    "            for word in tokens:\n",
    "                if word not in stopwords.words('english'):\n",
    "                    tokens_noStops.append(word)\n",
    "\n",
    "\n",
    "            #Lemmatize each token in the string\n",
    "            lemmaTokens = []\n",
    "\n",
    "            for t in tokens_noStops:\n",
    "                temp_t = lemmatizer.lemmatize(t)\n",
    "                lemmaTokens.append(temp_t)\n",
    "\n",
    "            #Convert integers to numbers\n",
    "            tokens_final = replace_numbers(lemmaTokens)\n",
    "            \n",
    "            print(tokens_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
